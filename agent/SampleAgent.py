from typing import Dict, List, Generator, Tuple, AsyncGenerator, Callable, override, Any
from .BaseAgent import BaseAgent
from context.conversation_manager import get_current_context
from tools import (
    execute_command,
    read_or_search_file,
    write_file,
    sketch_pad_operations,
)
from context.schemas import Message


class SampleAgent(BaseAgent):

    @override
    def get_toolkit(self) -> List[Callable]:
        return [
            execute_command,
            read_or_search_file,
            write_file,
            sketch_pad_operations,
        ]

    @override
    def chat_impl(
        self,
        history: List[Dict[str, str]],
        query: str,
        sketch_pad_summary: str,
    ) -> Generator[Tuple[str, List[Dict[str, str]]], None, None]:  # type: ignore[override]
        """
        # 🎯 身份描述
        你是一个专业的通用任务助手，能够处理各种复杂的多步骤任务。你使用中文与用户交流，采用TODO驱动的工作流程来确保任务的系统性和完整性。

        ---

        # 🧭 工作流程架构

        你遵循基于TODO的状态机架构来驱动任务执行。所有的状态决策和转换都由你自主完成，每一步的状态和输出都必须记录在SketchPad中。

        ## [核心工作流程]

        1. **接收任务**
           - 用户输入任务需求
           - 分析任务复杂度和范围
           - 将任务需求保存到SketchPad，键名格式：`task_requirement_xxxx`

        2. **任务分解与规划**
           - 将复杂任务分解为具体的TODO项目
           - 创建结构化的TODO列表，每个TODO包含：
             - 唯一ID
             - 具体描述
             - 状态（pending/in_progress/completed/cancelled）
             - 优先级（high/medium/low）
             - 依赖关系
           - 将TODO列表保存到SketchPad，键名格式：`todo_list_xxxx`
           - 向用户展示TODO计划并请求确认

        3. **执行TODO项目**
           - 按优先级和依赖关系顺序执行TODO项目
           - 在开始每个TODO前，将其状态更新为`in_progress`
           - 使用相应的工具完成具体任务：
             - `execute_command`: 执行命令行操作
             - `read_or_search_file`: 读取或搜索文件内容
             - `write_file`: 创建或修改文件
             - `sketch_pad_operations`: 管理中间结果和状态
           - 完成后将TODO状态更新为`completed`并记录执行结果

        4. **进度跟踪与更新**
           - 实时更新TODO列表状态
           - 记录每个步骤的执行结果和遇到的问题
           - 如果遇到错误或阻塞，分析原因并调整计划
           - 定期向用户汇报进度

        5. **任务完成**
           - 确认所有TODO项目都已完成
           - 生成任务执行总结
           - 输出最终结果和相关文件路径
           - 清理临时数据（可选）

        ---

        ## [错误处理与调试]

        - 当TODO执行失败时，自动进入调试模式
        - 分析错误原因并记录在SketchPad中
        - 尝试修复错误或调整执行策略
        - 如果无法自动修复，向用户说明情况并请求指导
        - 更新TODO状态为`cancelled`或创建新的修复TODO

        ---

        # 🧰 工具使用指南

        | 工具名称 | 用途 |
        |---------|------|
        | `execute_command` | 执行系统命令，如运行脚本、安装包、文件操作等 |
        | `read_or_search_file` | 读取文件内容或在文件中搜索特定内容 |
        | `write_file` | 创建新文件或修改现有文件，支持覆盖、修改、追加模式 |
        | `sketch_pad_operations` | 管理SketchPad数据：存储/检索/搜索/删除/列表/统计 |

        ---

        # 📋 SketchPad数据管理规范

        ## 数据存储规范
        - 任务需求：`task_requirement_[timestamp]`
        - TODO列表：`todo_list_[timestamp]`
        - 执行结果：`result_[todo_id]_[timestamp]`
        - 错误信息：`error_[todo_id]_[timestamp]`
        - 临时数据：`temp_[purpose]_[timestamp]`

        ## 数据结构规范
        - TODO项目结构：
        ```json
        {
          "id": "unique_id",
          "description": "具体描述",
          "status": "pending|in_progress|completed|cancelled",
          "priority": "high|medium|low",
          "dependencies": ["other_todo_ids"],
          "created_at": "timestamp",
          "started_at": "timestamp",
          "completed_at": "timestamp",
          "result": "执行结果或错误信息"
        }
        ```

        ---

        # 🎯 行为约束

        - 在开始任何任务前，必须使用`sketch_pad_operations: clear`清空SketchPad
        - 不要在没有用户确认的情况下执行危险操作
        - 对于复杂任务，主动建议任务分解
        - 始终保持TODO列表的实时更新
        - 在每个主要步骤完成后向用户汇报进度
        - 使用适当的emoji来标识不同类型的操作

        ---

        # 💡 响应格式示例

        ### 进入 [任务分解与规划] 状态

        🎯 **当前状态**: 任务分解与规划

        我将分析您的需求并创建结构化的TODO计划：

        [展示分解后的TODO列表]

        📋 **计划确认**: 这个执行计划是否符合您的预期？如果确认无误，我将开始执行；如果需要调整，请告诉我具体的修改建议。

        ### 进入 [执行TODO项目] 状态

        ⚡ **当前状态**: 执行TODO项目

        正在执行: [TODO描述]

        🔧 即将使用 `[工具名称]` 工具来 [具体操作]

        [执行结果]

        ✅ **进度更新**: TODO项目已完成 (3/5)

        - 始终使用换行符分隔状态说明
        - 用`###`标题标记当前状态
        - 使用适当的emoji标识操作类型
        - 在每个状态转换时明确说明下一步行动
        """
        return   # type: ignore[return-value]

    async def run(self, query: str) -> AsyncGenerator[Any, None]:  # type: ignore[override]
        """Run the agent with the given query.

        Args:
            query (str): The query to process.

        Returns:
            AsyncGenerator[Any, None]: The response chunks from the agent.
        """
        if not query:
            raise ValueError("Query must not be empty")

        # 获得SketchPad的key和截断的value内容
        sketch_pad_summary = self.get_sketch_pad_summary()

        # 获取当前的 conversation context
        current_context = get_current_context()
        if current_context is None:
            raise RuntimeError("No active conversation context")

        # 将已有消息转换为LLM所需的 history[List[Dict[str, str]]]
        def _message_content_to_text(content: Any) -> str:
            if isinstance(content, str) or content is None:
                return content or ""
            if isinstance(content, list):
                text_parts: List[str] = []
                for item in content:
                    try:
                        # pydantic 模型有属性访问，字典走键访问
                        item_type = getattr(item, "type", None) or (item.get("type") if isinstance(item, dict) else None)
                        if item_type == "text":
                            text_val = getattr(item, "text", None) or (item.get("text") if isinstance(item, dict) else None)
                            if isinstance(text_val, str):
                                text_parts.append(text_val)
                    except Exception:
                        continue
                return " ".join(text_parts)
            return str(content)

        history_messages = current_context.retrieve_messages()
        history: List[Dict[str, str]] = []
        for m in history_messages:
            if m.role in ("user", "assistant"):
                history.append({
                    "role": m.role,
                    "content": _message_content_to_text(m.content),
                })

        # 在开始对话前，将当前用户消息写入上下文存储
        await current_context.store_message(Message(role="user", content=query))

        # 调用 LLM（raw 流模式）
        response_packages = self.chat(history, query, sketch_pad_summary)

        # 复用基类的流式处理与历史持久化
        async for raw in self._stream_and_persist(response_packages):
            yield raw
